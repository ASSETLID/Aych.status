#!/usr/bin/python

import yaml
try :
    from yaml import CBaseLoader as yamlLoader
except ImportError:
    from yaml import BaseLoader as yamlLoader
    warning('YAML C-library not available, falling back to python')

try :
    import cPickle as pickle
except ImportError:
    import pickle
    warning('Pickle C-library not available, falling back to python')

import os.path
from codecs import open
import fnmatch
import os, signal
import copy
import gc
import argparse
import csv
import datetime as dt
import json
import pydot

from subprocess import Popen, PIPE, STDOUT
from progressbar import Bar, Percentage, ProgressBar

from email.utils import parseaddr, formatdate

import matplotlib
matplotlib.use('Agg') 
import matplotlib.pyplot as plt
from matplotlib import dates
from matplotlib.dates import DateFormatter, date2num

from itertools import groupby, izip_longest
from operator import itemgetter, attrgetter, methodcaller

from collections import defaultdict
from collections import OrderedDict

import pprint
pp = pprint.PrettyPrinter(indent=4)

from jinja2 import Environment, FileSystemLoader, FileSystemBytecodeCache

import urllib
from markupsafe import Markup

THIS_DIR = os.path.dirname(os.path.abspath(__file__))
bcc = FileSystemBytecodeCache('/tmp/jinja_cache', '%s.cache')
j2_env = Environment(loader=FileSystemLoader(THIS_DIR),trim_blocks=True,bytecode_cache=bcc,cache_size=100)
datefmt = "%a %b %d %H:%M:%S %Z %Y"

def urlencode_filter(s):
    if type(s) == 'Markup':
        s = s.unescape()
    s = s.encode('utf8')
    s = urllib.quote_plus(s)
    return Markup(s)
j2_env.filters['urlencode'] = urlencode_filter

def bts_filter(s):
    text = "Dear Maintainer. The package %s is not usable. \nPlease check <a http://ows.irill.org/packages/%s> OWS for details</a>" % s
    title = "OWS. The package %s is partially broken" % s
    url = "https://github.com/ocaml/opam-repository/issues/new"
    return url + "?title=%s&body=%s" % (urllib.quote_plus(title), urllib.quote_plus(body))
j2_env.filters['bts_filter'] = bts_filter

class DateTimeEncoder(json.JSONEncoder):
    def default(self, o):
        if isinstance(o, dt.datetime) :
            return str(o.isoformat())
        try :
            r = json.JSONEncoder.default(self, o)
        except TypeError, x :
            return  x
        return r

def versiontuple(v):
    filled = []
    for point in v.split("."):
       filled.append(point.zfill(8))
    return tuple(filled)

def save_page(output,fname):
    with open(fname, 'w', encoding='utf-8') as f:
        f.write(output)
    f.close()

def parse(f):
    data = yaml.load(f, Loader=yamlLoader)
    d = {}
    if 'broken-packages' in data : 
        data = { x.replace('-', '_'): data[x] for x in data.keys() }
        d['broken_packages'] = int(data['broken_packages'])
        d['total_packages'] = int(data['total_packages'])
        d['switch'] = data['ocaml_switch']
        d['date'] = dt.datetime.strptime(data['git_date'],datefmt)
        d['commit'] = data['git_commit']
        d['title'] = data['git_title']
        d['author'] = data['git_author']
        d['summary'] = data['summary']
        d['report'] = {}
        for name, group in groupby(data['report'], lambda x: x['package']):
            for p in group:
                d['report'].setdefault(name,[p]).append(p)
    return d

def plot(options,history):
    print "Computing Graph"
    output = os.path.join(options['dirname'],"plot.png")
    fig = plt.figure()
    graph = fig.add_subplot(111)
    switches = set()
    hs = {}
    
    for e in sorted(history,key=lambda x:x[0]):
        t = e[0]
        for switch,(total,broken,ok) in e[1].iteritems():
            hs.setdefault(switch,[]).append((date2num(t),ok))
            switches.add(switch)

    for s in switches :
        d = zip(*(hs[s]))
        graph.plot_date(d[0],d[1],",-",label=s)

    plt.legend(loc='upper left')
    plt.title('Installable Package versions vs Time')
    fig.autofmt_xdate()
    plt.savefig(output)

def aggregate(d):
    aggregatereport = {}
    aggregatesummary = { 'conflict' : {} , 'missing' : {} }
    bymaintainer = {}
    summary = {}
    date,title,author,commit,totals = None,None,None,None,{}
    for report in d :
        if report :
            date = report['date']
            title = report['title']
            author = report['author']
            commit = report['commit']
            switch = report['switch']
            tp,bp = report['total_packages'],report['broken_packages']
            totals[switch] = (tp,bp,tp - bp)
            for a in report['summary'] :
                if 'missing' in a :
                    breaks = int(a['missing']['breaks'])
                    pkg = (a['missing']['pkg']['package'],a['missing']['pkg']['version'])
                    s = { 'breaks' : breaks , 'packages' : a['missing']['packages'] }
                    aggregatesummary['missing'].setdefault(pkg,{ switch :  s }).update({ switch :  s })
                    aggregatesummary['missing'][pkg]['total'] = aggregatesummary['missing'][pkg].get('total',0) + breaks
                elif 'conflict' in a :
                    pkg1 = (a['conflict']['pkg1']['package'],a['conflict']['pkg1']['version'])
                    pkg2 = (a['conflict']['pkg2']['package'],a['conflict']['pkg2']['version'])
                    breaks = int(a['conflict']['breaks'])
                    s = { 'breaks' : breaks , 'packages' : a['conflict']['packages'] }
                    aggregatesummary['conflict'].setdefault((pkg1,pkg2),{ switch :  s }).update({ switch :  s })
                    aggregatesummary['conflict'][(pkg1,pkg2)]['total'] = aggregatesummary['conflict'][(pkg1,pkg2)].get('total',0) + breaks

            for name, l in report['report'].iteritems() :
                if name not in aggregatereport :
                    aggregatereport[name] = OrderedDict()
                    summary[name] = {}

                status = {'ok' : 0, 'broken' : 0}
                for s,group in groupby(l, lambda p: p['status']) :
                    status[s] = len(list(group))

                if status['ok'] == len(l) :
                    summary[name][switch] = "ok"
                elif status['broken'] == len(l) :
                    summary[name][switch] = "broken"
                else :
                    summary[name][switch] = "partial"

                for package in l :
                    ver = package['version']
                    r = package['reasons'] if package['status'] == "broken" else None
                    direct = None
                    indirect = None
                    dc,dm = [],[] # direct conflicts, direct missing
                    idc,idm = [], {} # indirect conflicts, indirect missing
                    package['maintainer'] = package['maintainer'].replace(' and ',' , ')
                    if 'maintainer' in package:
                        (namestr,addr) = parseaddr(package['maintainer'].split(',')[0])
                        if len(addr.encode('utf8')) > 0 :
                            maintainer = addr
                        elif len(namestr.encode('utf8')) > 0 :
                            maintainer = urlencode_filter(package['maintainer'])
                        else :
                            maintainer = "orphan"
                    else :
                        maintainer = "orphan"
                    info = {'switch' : switch ,
                            'name' : name ,
                            'ver' : ver,
                            'status' : package['status'] ,
                            'maintainer' : package['maintainer'] if not maintainer == "orphan" else "orphan"}
                    bymaintainer.setdefault(maintainer,[info]).append(info)
                    if 'reasons' in package :
                        for p in package['reasons'] :
                            if 'missing' in p :
                                pkgname = p['missing']['pkg']['package']
                                pkgvers = p['missing']['pkg']['version']
                                unsatdep = p['missing']['pkg']['unsat-dependency']
                                if pkgname == name :
                                    direct = True
                                    indirect = False
                                    dm.append(unsatdep)
                                else :
                                    direct = False
                                    indirect = True
                                    if pkgvers not in idm.setdefault(pkgname,[pkgvers]) :
                                        idm.setdefault(pkgname,[pkgvers]).append(pkgvers)

                            if 'conflict' in p :
                                p1 = p['conflict']['pkg1']['package']
                                p2 = p['conflict']['pkg2']['package']
                                v1 = p['conflict']['pkg1']['version']
                                v2 = p['conflict']['pkg2']['version']
                                if p['conflict']['pkg1']['package'] == name or p['conflict']['pkg2']['package'] == name :
                                    direct = True
                                    indirect = False
                                    dc.append(((p1,v1),(p2,v2)))
                                else :
                                    direct = False
                                    indirect = True
                                    idc.append(((p1,v1),(p2,v2)))

                    p = (package['status'],(direct,indirect),dc,dm,idc,idm,r,maintainer)
                    aggregatereport[name].setdefault(ver, { switch : p }).update({ switch : p })

    summaryreport = {
            'broken' : 0, 'partial': 0, 'correct' : 0, 'totalnames' : len(aggregatereport),
            'totals' : totals, 'report' : summary, 'summary' : aggregatesummary,
            'date' : date, 'title' : title, 'author' : author, 'commit' : commit }

    switchnumber = len(d)
    for name,switches in summary.iteritems() :
        broken,correct,undefined,total_versions = 0,0,0,0
        aggregatereport[name] = OrderedDict(sorted(aggregatereport[name].items(),key=lambda x: versiontuple(x[0]),reverse=True))
        for version, results in aggregatereport[name].iteritems() :
            for s in switches :
                total_versions += 1
                if s in results :
                    if results[s][0] == "broken" :
                        broken += 1
                    else :
                        correct += 1
                else :
                    undefined += 1
        summaryreport['report'][name]['percent'] = int(100.0 * (float(broken) / float(total_versions)))
        if broken == total_versions - undefined :
            summaryreport['broken'] += 1
            summaryreport['report'][name]['status'] = "broken"
        elif correct == total_versions - undefined :
            summaryreport['correct'] += 1
            summaryreport['report'][name]['status'] = "ok"
        else :
            summaryreport['partial'] += 1
            summaryreport['report'][name]['status'] = "partial"

    summaryreport['report'] = OrderedDict(sorted(summaryreport['report'].items(), key=lambda x : x[1]['percent'],reverse=True))
    summaryreport['bymaintainer'] = bymaintainer
    summaryreport['summary']['missing'] = OrderedDict(sorted(summaryreport['summary']['missing'].items(), key=lambda x: x[1]['total'],reverse=True))
    summaryreport['summary']['conflict'] = OrderedDict(sorted(summaryreport['summary']['conflict'].items(), key=lambda x: x[1]['total'],reverse=True))

    return aggregatereport,summaryreport

# we assume the monotonicity of the opam repo
def weather(report, weather_yesterday) :
    weather = {}
    for p,v in report.iteritems() :
        if v['percent'] == 0 :
            weather_today = "sunny"
        elif v['percent'] < 0 and v['percent'] >= 20 :
            weather_today = "cloudy"
        else :
            weather_today = "stormy"
        if weather_yesterday is not None :
            if weather_yesterday == weather_today :
                weather[p] = [weather_today]
            else :
                weather[p] = [weather_yesterday, weather_today]
        else :
            weather[p] = [weather_today]
    return weather

def html_backlog(options,history,summaryreport):
    print "Compiling BackLog Page"
    shortdate = summaryreport['date'].strftime("%Y-%m-%d")
    commit = summaryreport['commit']
    template = j2_env.get_template('templates/backlog.html')
    output = template.render({'shortdate' : shortdate, 'commit' : commit, 'history': history, 'summary' : summaryreport})
    fname = os.path.join(options['dirname'],"backlog.html")
    save_page(output,fname)

def html_credits(options,summaryreport):
    print "Compiling Credits Page"
    shortdate = summaryreport['date'].strftime("%Y-%m-%d")
    commit = summaryreport['commit']
    template = j2_env.get_template('templates/credits.html')
    output = template.render({'shortdate' : shortdate, 'commit' : commit, 'summary' : summaryreport})
    fname = os.path.join(options['dirname'],"credits.html")
    save_page(output,fname)
 
def html_howto(options,summaryreport,switches):
    print "Compiling Howto Page"
    shortdate = summaryreport['date'].strftime("%Y-%m-%d")
    commit = summaryreport['commit']
    template = j2_env.get_template('templates/howto.html')
    output = template.render({'shortdate' : shortdate, 'commit' : commit,'switches': switches, 'summary' : summaryreport})
    fname = os.path.join(options['dirname'],"howto.html")
    save_page(output,fname)

def json_weather(options,summaryreport,aggregatereport):
    print "Compiling JSON Report ..."
    date = summaryreport['date']
    r = {}
    for name,versions in aggregatereport.iteritems() :
        for ver,data in versions.iteritems() :
            for switch,status in data.iteritems():
                (direct,indirect) = status[1]
                p = {'version' : ver, 'switch' : switch, 'status' : status[0]}
                if status[0] != 'ok' :
                    p['direct'] = direct

                r.setdefault(name,[]).append(p)

    data = {'date' : date, 'report' : r }
    json_string = json.dumps(data,cls=DateTimeEncoder,skipkeys=True,indent=4, separators=(',', ': '),sort_keys=True)
    save_page(json_string,os.path.join(options['targetdir'],'json',"weather.json"))

def html_dashboard(options,aggregatereport,summaryreport,switches):
    print "Compiling Dashboard Pages"
    shortdate = summaryreport['date'].strftime("%Y-%m-%d")
    commit = summaryreport['commit']
    pbar = ProgressBar(widgets=[Percentage(), Bar()], maxval=len(aggregatereport))
    template = j2_env.get_template('templates/packagedashboard.html')

    i = 0
    pbar.start()
    summary = copy.copy(summaryreport)
    dashboardtable = []
    for maintainer,packages in sorted(summaryreport['bymaintainer'].items(), key=lambda (x,y) : x.lower()) :
        i += 1
        pbar.update(i)
        items = []
        del summary['report'];
        summary['report'] = {}
        maintainerstr = ""
        for pkg in packages :
            name = pkg['name']
            maintainerstr = pkg['maintainer']
            summary['report'][name] = summaryreport['report'][name]
        summary['report'] = OrderedDict(sorted(summary['report'].items(), key=lambda x : x[1]['percent'],reverse=True))

        dashboardtable.append((maintainer,{ 'maintainer' : maintainerstr, 'totalnames' : len(summary['report']), 'broken': 0, 'partial': 0 }))

        output = template.render({
            'shortdate' : shortdate, 'commit' : commit, 
            'maintainer' : maintainerstr, 'summary' : summary, 
            'switches': switches, 'allpackages' : True})
        fname = os.path.join(options['dirname'],"dashboard","%s.html" % maintainer)
        save_page(output,fname)
    pbar.finish()

    template = j2_env.get_template('templates/dashboardtable.html')
    output = template.render({'shortdate' : shortdate, 'commit' : commit, 'bymaintainer' : dashboardtable, 'switches': switches})
    fname = os.path.join(options['dirname'],"dashboard.html")
    save_page(output,fname)

def html_weather(options,aggregatereport,summaryreport,switches):
    print "Compiling Weather Page"
    print "Compiling modal overlays and standalone packages' pages"
    pbar = ProgressBar(widgets=[Percentage(), Bar()], maxval=len(aggregatereport))
    shortdate = summaryreport['date'].strftime("%Y-%m-%d")
    commit = summaryreport['commit']

    i = 0
    pbar.start()
    for name,versions in aggregatereport.iteritems() :
        i += 1
        pbar.update(i)
        templatemodal = j2_env.get_template('templates/packagemodal.html')
        output = templatemodal.render({
            'name' : name,
            'versions' : versions,
            'switches': switches,
            'date' : summaryreport['date'],
            'shortdate' : shortdate,
            'commit' : commit})
        fname = os.path.join(options['dirname'],"packages",name+"-modal.html")
        save_page(output,fname)

        templatepage = j2_env.get_template('templates/packagepage.html')
        output = templatepage.render({
            'name' : name, 
            'versions' : versions, 
            'switches': switches, 
            'date' : summaryreport['date'], 
            'shortdate' : shortdate, 'commit' : commit})
        fname = os.path.join(options['dirname'],"packages",name+"-page.html")
        save_page(output,fname)
    pbar.finish()

    if not options['nosvg'] :
        print "Compiling SVG files..."
        i = 0
        pbar.start()
        for name,versions in aggregatereport.iteritems() :
            i += 1
            pbar.update(i)

            for switch in switches :
                for version,result in versions.iteritems() :
                    if switch in result and result[switch][0] == 'broken' :
                        dotname = os.path.join(options['reportdir'],switch,"%s.%s.dot" % (name,version))
                        if os.path.exists(dotname) :
                            dotfile = pydot.graph_from_dot_file(dotname)
                            dotfile.write_svg(os.path.join(options['dirname'],switch,"%s.%s.svg" % (name,version)))
        pbar.finish()

    template = j2_env.get_template('templates/weather.html')

    output = template.render({'shortdate' : shortdate, 'commit' : commit, 'summary' : summaryreport, 'switches': switches, 'allpackages' : False})
    fname = os.path.join(options['dirname'],"index.html")
    save_page(output,fname)

    output = template.render({'shortdate' : shortdate, 'commit' : commit, 'summary' : summaryreport, 'switches': switches, 'allpackages' : True})
    fname = os.path.join(options['dirname'],"weather.html")
    save_page(output,fname)

def rss_weather(options,history,summaryreport):
    print "Generating RSS feed"
    template = j2_env.get_template('templates/maintainerfeed.rss')
    pbar = ProgressBar(widgets=[Percentage(), Bar()], maxval=len(summaryreport['bymaintainer']))

    i = 0
    pbar.start()
    for maintainer,packages in summaryreport['bymaintainer'].iteritems() :
        i += 1
        pbar.update(i)
        items = []
        maintainerstr = ""
        for date,bymaintainer in history :
            commit = summaryreport['commit']
            if maintainer in bymaintainer :
                description = []
                maintainerstr = bymaintainer[maintainer][0]['maintainer']
                for switch,l in groupby(bymaintainer[maintainer],key=lambda x : x['switch']):
                    description.append((switch,list(l)))
                items.append({
                    'date' : formatdate(float(date.strftime('%s'))),
                    'shortdate' : date.strftime("%Y-%m-%d"),
                    'commit' : commit,
                    'description' : description,})

        output = template.render({
            'baseurl' : options['baseurl'],
            'maintainer' : maintainer,
            'maintainerstr' : maintainerstr,
            'items' : items })
        fname = os.path.join(options['targetdir'],'rss','%s.rss' % maintainer)
        save_page(output,fname)
    pbar.finish()

def html_summary(options,summaryreport,switches):
    print "Compiling Summary Page"
    shortdate = summaryreport['date'].strftime("%Y-%m-%d")
    commit = summaryreport['commit']
    for t,s in summaryreport['summary'].iteritems() :
        if t == 'missing' :
            for (name,version),a in s.iteritems() :
                rows = []
                for sw,b in a.iteritems() :
                    l = []
                    if sw != 'total' :
                        for n,group in groupby(b['packages'], lambda p: p['package']) :
                            ll = map(lambda p: p['version'],list(group))
                            l.append((n,ll))
                        rows.append([sw] + l)
                rows = map(lambda x: list(x),izip_longest(*(sorted(rows,key=lambda x : x[0]))))
                template = j2_env.get_template('templates/packagelist.html')
                title = "%s %s (ows : %s)" % (name,version,summaryreport['date'])
                output = template.render({'title' : title, 'summary' : rows, 'switches': switches})
                fname = os.path.join(options['dirname'],"summary",name+version+".html")
                save_page(output,fname)
        if t == 'conflict' :
            for (pkg1,pkg2),a in s.iteritems() :
                rows = []
                for sw,b in a.iteritems() :
                    l = []
                    if sw != 'total' :
                        for n,group in groupby(b['packages'], lambda p: p['package']) :
                            ll = map(lambda p: p['version'],list(group))
                            l.append((n,ll))
                        rows.append([sw] + l)
                rows = map(lambda x: list(x),izip_longest(*(sorted(rows,key=lambda x : x[0]))))
                template = j2_env.get_template('templates/packagelist.html')
                title = "%s %s # %s %s (ows : %s)" % (pkg1[0],pkg1[1],pkg2[0],pkg2[1],summaryreport['date'])
                output = template.render({'title': title, 'summary' : rows, 'switches': switches})
                fname = os.path.join(options['dirname'],"summary",pkg1[0]+pkg1[1]+"-"+pkg2[0]+pkg2[1]+".html")
                save_page(output,fname)

    template = j2_env.get_template('templates/summary.html')
    output = template.render({'shortdate' : shortdate, 'commit' : commit,'summary' : summaryreport, 'switches': switches})
    fname = os.path.join(options['dirname'],"summary.html")
    save_page(output,fname)

def setup(summaryreport,switches,targetdir):
    shortdate = summaryreport['date'].strftime("%Y-%m-%d")
    dirname = os.path.join(targetdir,shortdate,summaryreport['commit'])
    if not os.path.exists("/tmp/jinja_cache") :
        os.makedirs("/tmp/jinja_cache")
    rss = os.path.join(targetdir,'rss')
    if not os.path.exists(rss) :
        os.makedirs(rss)
    json = os.path.join(targetdir,'json')
    if not os.path.exists(json) :
        os.makedirs(json)
    if not os.path.exists(dirname) :
        os.makedirs(dirname)
    summary = os.path.join(dirname,'summary')
    if not os.path.exists(summary) :
        os.makedirs(summary)
    packages = os.path.join(dirname,'packages')
    if not os.path.exists(packages) :
        os.makedirs(packages)
    dashboards = os.path.join(dirname,'dashboard')
    if not os.path.exists(dashboards) :
        os.makedirs(dashboards)
    for switch in switches :
        switchname = os.path.join(dirname,switch)
        if not os.path.exists(switchname) :
            os.makedirs(switchname)
    return dirname

def load_or_parse(reportdir,nocache):
    picklefile = os.path.join(reportdir,'data.pickle')

    if nocache and os.path.exists(picklefile) :
        os.remove(picklefile)

    if os.path.exists(picklefile) :
        print "Load Cache"
        with open(picklefile,'r') as f :
            (switches,ar,sr) = pickle.load(f)
    else :
        report = []
        switches = []
        for root, dirs, files in os.walk(reportdir, topdown=False):
            for name in fnmatch.filter(files, "*.yaml"):
                fname = os.path.join(root, name)
                print "Parse ", fname
                with open(fname) as dataset :
                    r = parse(dataset)
                    if r : 
                        switches.append(r['switch'])
                        report.append(r)
                    dataset.close()
            gc.collect()

        print "Aggregating Data"
        (ar,sr) = aggregate(report)
        s = signal.signal(signal.SIGINT, signal.SIG_IGN)
        with open(picklefile,'wb') as f :
            pickle.dump((switches,ar,sr),f)
            f.close()
        signal.signal(signal.SIGINT, s)
    switches = sorted(switches,key=lambda r: versiontuple(r),reverse=True)
    return (switches,ar,sr)

def load_history(filename):
    print "Load History ",filename
    h = {}
    if os.path.exists(filename) :
        with open(filename,'r') as f :
            h = pickle.load(f)
            f.close()
    newsummary = {}
    if 'switches' in h :
        newsummary = {
                'switches'     : h['switches'] ,
                'plotdata'     : dict(h['plotdata']),
                'bymaintainer' : dict(h['bymaintainer']),
                'weather'      : h['weather'], 
                'backlog'      : dict(h['backlog']) }

    return newsummary

def save_history(filename,history,sr,switches):
    import copy
    print "Saving History "
    date = sr['date']
    plotdata = (date,sr['totals'])
    bymaintainer = (date,sr['bymaintainer'])
    weather = (date,copy.copy(sr['weather']))
    summary = {
            'commit'     : sr['commit'],
            'author'     : sr['author'],
            'title'      : sr['title'], 
            'broken'     : sr['broken'], 
            'totalnames' : sr['totalnames'], 
            'partial'    : sr['partial'] }
    backlog = (date,summary)

    plotdatalist = history.get('plotdata',{}).items()
    plotdatalist.insert(0,plotdata)
    plotdatalist = sorted(plotdatalist,key=lambda x:x[0])
    
    bymaintainerlist = history.get('bymaintainer',{}).items()
    bymaintainerlist.insert(0,bymaintainer)
    bymaintainerlist = sorted(bymaintainerlist,key=lambda x:x[0],reverse=True)[:10]

    backloglist = history.get('backlog',{}).items()
    backloglist.insert(0,backlog)
    backloglist = sorted(backloglist,key=lambda x:x[0],reverse=True)[:10]

    newsummary = {
            'switches'     : switches ,
            'plotdata'     : plotdatalist,
            'bymaintainer' : bymaintainerlist,
            'weather'      : weather, 
            'backlog'      : backloglist }

    print "History stats :"
    print " Plotdata : %d" % len(newsummary['plotdata'])
    print " ByMaintainer : %d" % len(newsummary['bymaintainer'])
    print " BackLog : %d" % len(newsummary['backlog'])
    print " Plot Dates : %s %s" % (min(dict(newsummary['plotdata']).keys()),max(dict(newsummary['plotdata']).keys()))
    print " BackLog Dates  %s %s" % (min(dict(newsummary['backlog']).keys()),max(dict(newsummary['backlog']).keys()))
    print " ByMaintainer Dates  %s %s" % (min(dict(newsummary['bymaintainer']).keys()),max(dict(newsummary['bymaintainer']).keys()))

    s = signal.signal(signal.SIGINT, signal.SIG_IGN)
    with open(filename,'wb') as f :
        pickle.dump(newsummary,f)
        f.close()
    signal.signal(signal.SIGINT, s)

def source(owsconf):

    command = ['bash', '-c', 'set -a && source %s && env' % owsconf ]
    proc = Popen(command, stdout=PIPE)
    for line in proc.stdout:
      (key, _, value) = line.partition("=")
      os.environ[key] = value.strip()
    proc.communicate()

    return os.environ

def main():
    parser = argparse.ArgumentParser(description='create ows static pages')
    #parser.add_argument('-v', '--verbose')
    #parser.add_argument('-d', '--debug', action='store_true', default=False)
    parser.add_argument('--nopages', action='store_true', help="Compute only json and rss feeds", default=False)
    parser.add_argument('--nocache', action='store_true', help="Do not use cache files (if any)", default=False)
    parser.add_argument('--nosvg', action='store_true', help="Do not generate svg files", default=False)
    parser.add_argument('--baseurl', type=str, help="base url", default="http://localhost:8000/")
    parser.add_argument('--targetdir', type=str, help="target html directory", default="html")
    parser.add_argument('--history', type=str, help="history database", default=os.path.join("reports",'history.pickle'))
    parser.add_argument('reportdir', type=str, nargs=1, help="dataset")
    args = parser.parse_args()

    print "Considering ", args.reportdir[0]
    (switches,ar,sr) = load_or_parse(args.reportdir[0],args.nocache)
    options = {
            'dirname' : setup(sr,switches,args.targetdir),
            'targetdir' : args.targetdir,
            'baseurl' : args.baseurl ,
            'reportdir' : args.reportdir[0],
            'nosvg' : args.nosvg}

    h = load_history(args.history)
    if 'weather' in sr :
        sr['weather'] = weather(sr['report'],sr['weather'])
    else :
        sr['weather'] = {}

    rss_weather(options,h.get('bymaintainer',{}).items(),sr)
    json_weather(options,sr,ar)
    
    if args.nopages == False :
        html_weather(options,ar,sr,switches)
        html_dashboard(options,ar,sr,switches)
        html_summary(options,sr,switches)
        html_howto(options,sr,switches)
        html_credits(options,sr)
        html_backlog(options,h.get('backlog',{}).items(),sr)
        plot(options,h.get('plotdata',{}).items())

    save_history(args.history,h,sr,switches)

    print

if __name__ == '__main__':
    main()
